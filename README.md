# Random User Pipeline

This project aims to create a pipeline for generating random user data.

## Overview

The Random User Pipeline project provides a systematic way to generate, process, and analyze random user data. The pipeline is designed to be modular and easily extendable.

## Pipeline Diagram

![Pipeline Diagram](./pipeline.png)

## Technologies Used

- **Apache Airflow**: Used for orchestrating and scheduling the data pipeline.
- **Apache Kafka**: Used as a distributed streaming platform to handle real-time data streams.
- **Apache ZooKeeper**: Used to coordinate and manage the Kafka cluster.
- **Apache Spark**: Used for processing and analyzing large data sets in a distributed environment.
- **PostgreSQL**: Used as the database for storing and managing user data.
- **Cassandra**: Used as a NoSQL database for high availability and scalability.
- **Docker**: Used for containerization to ensure consistent environments for development and deployment.
- **Python**: Used for coding the project up.

## Features

- **Data Generation**: Generate random user data with various attributes.
- **Data Processing**: Clean, transform, and prepare data for analysis.
- **Data Analysis**: Perform basic analysis and visualizations on the processed data.

